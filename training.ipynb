{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 1, 8, 1001), (150, 1))"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torcheeg\n",
    "import numpy as np\n",
    "from torcheeg.models import EEGNet\n",
    "\n",
    "#data loader\n",
    "signal = np.load('idle.npy')\n",
    "epochs_num = signal.shape[0]\n",
    "label = np.zeros((epochs_num, 1))\n",
    "signal = np.vstack([signal, np.load('box.npy')])\n",
    "label = np.vstack([label, np.zeros((epochs_num, 1)) + 1])\n",
    "# signal = np.vstack([signal, np.load('pen.npy')])\n",
    "# label = np.vstack([label, np.zeros((epochs_num, 1)) + 2])\n",
    "\n",
    "signal = np.vstack([signal, np.load('idle2.npy')])\n",
    "epochs_num = 30\n",
    "label = np.vstack([label, np.zeros((epochs_num, 1))])\n",
    "signal = np.vstack([signal, np.load('box2.npy')])\n",
    "label = np.vstack([label, np.zeros((epochs_num, 1)) + 1])\n",
    "# signal = np.vstack([signal, np.load('pen2.npy')])\n",
    "# label = np.vstack([label, np.zeros((epochs_num, 1)) + 2])\n",
    "\n",
    "signal = np.vstack([signal, np.load('idle3.npy')])\n",
    "epochs_num = 25\n",
    "label = np.vstack([label, np.zeros((epochs_num, 1))])\n",
    "signal = np.vstack([signal, np.load('box3.npy')])\n",
    "label = np.vstack([label, np.zeros((epochs_num, 1)) + 1])\n",
    "# signal = np.vstack([signal, np.load('pen3.npy')])\n",
    "# label = np.vstack([label, np.zeros((epochs_num, 1)) + 2])\n",
    "\n",
    "\n",
    "\n",
    "signal = np.expand_dims(signal, 1)\n",
    "signal.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 1, 8, 1001) (135, 1) (15, 1, 8, 1001) (15, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "xt, xv, yt, yv = train_test_split(signal, label, test_size = 0.1, random_state = 42, stratify = label)\n",
    "print(xt.shape, yt.shape, xv.shape, yv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | loss 0.025657398612410932 - accuracy 0.5259259259259259\n",
      "Epoch   2 | loss 0.025673809757939092 - accuracy 0.4222222222222222\n",
      "Epoch   3 | loss 0.025667112844961662 - accuracy 0.5185185185185185\n",
      "Epoch   4 | loss 0.025642524383686208 - accuracy 0.4074074074074074\n",
      "Epoch   5 | loss 0.02564128416555899 - accuracy 0.48148148148148145\n",
      "Epoch   6 | loss 0.025656708523079202 - accuracy 0.5037037037037037\n",
      "Epoch   7 | loss 0.025671517848968504 - accuracy 0.4740740740740741\n",
      "Epoch   8 | loss 0.0256521154333044 - accuracy 0.5851851851851851\n",
      "Epoch   9 | loss 0.025633702013227674 - accuracy 0.48148148148148145\n",
      "Epoch  10 | loss 0.025642739401923284 - accuracy 0.5259259259259259\n",
      "Epoch  11 | loss 0.025654402485600223 - accuracy 0.48148148148148145\n",
      "Epoch  12 | loss 0.025660877757602268 - accuracy 0.5407407407407407\n",
      "Epoch  13 | loss 0.02563913972289474 - accuracy 0.5333333333333333\n",
      "Epoch  14 | loss 0.02565738006874367 - accuracy 0.45925925925925926\n",
      "Epoch  15 | loss 0.0256022987542329 - accuracy 0.48148148148148145\n",
      "Epoch  16 | loss 0.025641372027220548 - accuracy 0.5037037037037037\n",
      "Epoch  17 | loss 0.025642956186223913 - accuracy 0.5259259259259259\n",
      "Epoch  18 | loss 0.025640465595104075 - accuracy 0.562962962962963\n",
      "Epoch  19 | loss 0.025618674136974193 - accuracy 0.5259259259259259\n",
      "Epoch  20 | loss 0.025626998919027824 - accuracy 0.5259259259259259\n",
      "Epoch  21 | loss 0.025642694808818676 - accuracy 0.5259259259259259\n",
      "Epoch  22 | loss 0.025619800002486617 - accuracy 0.5333333333333333\n",
      "Epoch  23 | loss 0.025615942036664046 - accuracy 0.4888888888888889\n",
      "Epoch  24 | loss 0.02565590496416445 - accuracy 0.4666666666666667\n",
      "Epoch  25 | loss 0.025625659359825984 - accuracy 0.43703703703703706\n",
      "Epoch  26 | loss 0.025600794509605125 - accuracy 0.5333333333333333\n",
      "Epoch  27 | loss 0.025633909967210558 - accuracy 0.5259259259259259\n",
      "Epoch  28 | loss 0.025585598415798612 - accuracy 0.5333333333333333\n",
      "Epoch  29 | loss 0.02561590009265476 - accuracy 0.5185185185185185\n",
      "Epoch  30 | loss 0.025564020209842258 - accuracy 0.5703703703703704\n",
      "Epoch  31 | loss 0.025576691274289732 - accuracy 0.5481481481481482\n",
      "Epoch  32 | loss 0.02557143944281119 - accuracy 0.5703703703703704\n",
      "Epoch  33 | loss 0.02557327394132261 - accuracy 0.5481481481481482\n",
      "Epoch  34 | loss 0.025534500899138272 - accuracy 0.5333333333333333\n",
      "Epoch  35 | loss 0.025534593175958704 - accuracy 0.5037037037037037\n",
      "Epoch  36 | loss 0.025575841356206823 - accuracy 0.5407407407407407\n",
      "Epoch  37 | loss 0.025579349199930827 - accuracy 0.5703703703703704\n",
      "Epoch  38 | loss 0.02555373156512225 - accuracy 0.5481481481481482\n",
      "Epoch  39 | loss 0.02555858117562753 - accuracy 0.5259259259259259\n",
      "Epoch  40 | loss 0.025509228971269397 - accuracy 0.5555555555555556\n",
      "Epoch  41 | loss 0.025518763065338134 - accuracy 0.5481481481481482\n",
      "Epoch  42 | loss 0.025496727448922618 - accuracy 0.6370370370370371\n",
      "Epoch  43 | loss 0.025525304123207374 - accuracy 0.4888888888888889\n",
      "Epoch  44 | loss 0.02556606001324124 - accuracy 0.5111111111111111\n",
      "Epoch  45 | loss 0.025503014635156702 - accuracy 0.5333333333333333\n",
      "Epoch  46 | loss 0.02546157748610885 - accuracy 0.5407407407407407\n",
      "Epoch  47 | loss 0.025477053500987865 - accuracy 0.6\n",
      "Epoch  48 | loss 0.02548064214211923 - accuracy 0.5407407407407407\n",
      "Epoch  49 | loss 0.025440004578343143 - accuracy 0.5925925925925926\n",
      "Epoch  50 | loss 0.025472842322455513 - accuracy 0.5703703703703704\n",
      "Epoch  51 | loss 0.025482463395154035 - accuracy 0.5333333333333333\n",
      "Epoch  52 | loss 0.025451842502311424 - accuracy 0.5481481481481482\n",
      "Epoch  53 | loss 0.02539906854982729 - accuracy 0.5185185185185185\n",
      "Epoch  54 | loss 0.02539217648682771 - accuracy 0.5851851851851851\n",
      "Epoch  55 | loss 0.02539023690753513 - accuracy 0.6\n",
      "Epoch  56 | loss 0.025377989698339393 - accuracy 0.562962962962963\n",
      "Epoch  57 | loss 0.025467825377428973 - accuracy 0.5185185185185185\n",
      "Epoch  58 | loss 0.02537865064762257 - accuracy 0.5777777777777777\n",
      "Epoch  59 | loss 0.025401384742171677 - accuracy 0.5185185185185185\n",
      "Epoch  60 | loss 0.025337171996081317 - accuracy 0.5703703703703704\n",
      "Epoch  61 | loss 0.02534671668653135 - accuracy 0.5777777777777777\n",
      "Epoch  62 | loss 0.02540964550442166 - accuracy 0.562962962962963\n",
      "Epoch  63 | loss 0.025287244938038012 - accuracy 0.562962962962963\n",
      "Epoch  64 | loss 0.025424581986886484 - accuracy 0.5777777777777777\n",
      "Epoch  65 | loss 0.025292172255339446 - accuracy 0.562962962962963\n",
      "Epoch  66 | loss 0.025250744819641114 - accuracy 0.6\n",
      "Epoch  67 | loss 0.025313191060666686 - accuracy 0.5555555555555556\n",
      "Epoch  68 | loss 0.025194982246116354 - accuracy 0.6\n",
      "Epoch  69 | loss 0.025222085581885444 - accuracy 0.5777777777777777\n",
      "Epoch  70 | loss 0.025226036707560223 - accuracy 0.6296296296296297\n",
      "Epoch  71 | loss 0.025236806604597303 - accuracy 0.6\n",
      "Epoch  72 | loss 0.02517422879183734 - accuracy 0.6\n",
      "Epoch  73 | loss 0.025107233612625686 - accuracy 0.5925925925925926\n",
      "Epoch  74 | loss 0.02513309717178345 - accuracy 0.6444444444444445\n",
      "Epoch  75 | loss 0.02511195253442835 - accuracy 0.6222222222222222\n",
      "Epoch  76 | loss 0.025050403895201506 - accuracy 0.6074074074074074\n",
      "Epoch  77 | loss 0.025070152900837087 - accuracy 0.6296296296296297\n",
      "Epoch  78 | loss 0.025063333687958895 - accuracy 0.6148148148148148\n",
      "Epoch  79 | loss 0.025028658354723895 - accuracy 0.5851851851851851\n",
      "Epoch  80 | loss 0.024947072399987114 - accuracy 0.6296296296296297\n",
      "Epoch  81 | loss 0.024922650831717033 - accuracy 0.5925925925925926\n",
      "Epoch  82 | loss 0.02497137917412652 - accuracy 0.5925925925925926\n",
      "Epoch  83 | loss 0.024987853014910664 - accuracy 0.6148148148148148\n",
      "Epoch  84 | loss 0.024885656657042326 - accuracy 0.6\n",
      "Epoch  85 | loss 0.024941474420052987 - accuracy 0.5777777777777777\n",
      "Epoch  86 | loss 0.024652184380425348 - accuracy 0.6370370370370371\n",
      "Epoch  87 | loss 0.024644424738707364 - accuracy 0.6518518518518519\n",
      "Epoch  88 | loss 0.024672091007232666 - accuracy 0.6370370370370371\n",
      "Epoch  89 | loss 0.02469122189062613 - accuracy 0.6296296296296297\n",
      "Epoch  90 | loss 0.02484121675844546 - accuracy 0.6\n",
      "Epoch  91 | loss 0.02444096671210395 - accuracy 0.6148148148148148\n",
      "Epoch  92 | loss 0.024557332639341 - accuracy 0.6888888888888889\n",
      "Epoch  93 | loss 0.024631898049955015 - accuracy 0.6666666666666666\n",
      "Epoch  94 | loss 0.02457632135461878 - accuracy 0.6518518518518519\n",
      "Epoch  95 | loss 0.024343134738780834 - accuracy 0.6074074074074074\n",
      "Epoch  96 | loss 0.024198317969286884 - accuracy 0.6592592592592592\n",
      "Epoch  97 | loss 0.024395468499925403 - accuracy 0.6444444444444445\n",
      "Epoch  98 | loss 0.02430443322217023 - accuracy 0.6592592592592592\n",
      "Epoch  99 | loss 0.024303654829661053 - accuracy 0.5851851851851851\n",
      "Epoch 100 | loss 0.02461856206258138 - accuracy 0.6148148148148148\n",
      "Epoch 101 | loss 0.024223455676326045 - accuracy 0.6222222222222222\n",
      "Epoch 102 | loss 0.02423678680702492 - accuracy 0.6222222222222222\n",
      "Epoch 103 | loss 0.02433709215234827 - accuracy 0.6444444444444445\n",
      "Epoch 104 | loss 0.02409885945143523 - accuracy 0.6444444444444445\n",
      "Epoch 105 | loss 0.023619839438685664 - accuracy 0.674074074074074\n",
      "Epoch 106 | loss 0.02399185586858679 - accuracy 0.6222222222222222\n",
      "Epoch 107 | loss 0.023742625448438855 - accuracy 0.5851851851851851\n",
      "Epoch 108 | loss 0.023584934958705197 - accuracy 0.6592592592592592\n",
      "Epoch 109 | loss 0.023706458233020925 - accuracy 0.6592592592592592\n",
      "Epoch 110 | loss 0.023605005829422564 - accuracy 0.6444444444444445\n",
      "Epoch 111 | loss 0.023223355964378075 - accuracy 0.6666666666666666\n",
      "Epoch 112 | loss 0.023275867656425194 - accuracy 0.6888888888888889\n",
      "Epoch 113 | loss 0.023332188306031405 - accuracy 0.6444444444444445\n",
      "Epoch 114 | loss 0.023375992863266557 - accuracy 0.6666666666666666\n",
      "Epoch 115 | loss 0.023349367689203333 - accuracy 0.6444444444444445\n",
      "Epoch 116 | loss 0.02343079469822071 - accuracy 0.6370370370370371\n",
      "Epoch 117 | loss 0.023119122010690194 - accuracy 0.6814814814814815\n",
      "Epoch 118 | loss 0.02334331892154835 - accuracy 0.674074074074074\n",
      "Epoch 119 | loss 0.022714121694918033 - accuracy 0.674074074074074\n",
      "Epoch 120 | loss 0.022921906577216253 - accuracy 0.6518518518518519\n",
      "Epoch 121 | loss 0.02295294646863584 - accuracy 0.6814814814814815\n",
      "Epoch 122 | loss 0.022845562740608498 - accuracy 0.6592592592592592\n",
      "Epoch 123 | loss 0.022918811992362693 - accuracy 0.6518518518518519\n",
      "Epoch 124 | loss 0.022789807672853823 - accuracy 0.6592592592592592\n",
      "Epoch 125 | loss 0.022894748051961265 - accuracy 0.6814814814814815\n",
      "Epoch 126 | loss 0.02282598680920071 - accuracy 0.6592592592592592\n",
      "Epoch 127 | loss 0.02230172046908626 - accuracy 0.6592592592592592\n",
      "Epoch 128 | loss 0.022704008332005254 - accuracy 0.6666666666666666\n",
      "Epoch 129 | loss 0.02213832272423638 - accuracy 0.6888888888888889\n",
      "Epoch 130 | loss 0.022147559678113018 - accuracy 0.6962962962962963\n",
      "Epoch 131 | loss 0.0224203211289865 - accuracy 0.6666666666666666\n",
      "Epoch 132 | loss 0.021861827815020527 - accuracy 0.6518518518518519\n",
      "Epoch 133 | loss 0.022098688505314015 - accuracy 0.6444444444444445\n",
      "Epoch 134 | loss 0.021679522814574064 - accuracy 0.7037037037037037\n",
      "Epoch 135 | loss 0.02164217586870547 - accuracy 0.6518518518518519\n",
      "Epoch 136 | loss 0.021880637716363976 - accuracy 0.6888888888888889\n",
      "Epoch 137 | loss 0.021633815544622917 - accuracy 0.6814814814814815\n",
      "Epoch 138 | loss 0.021614975620199133 - accuracy 0.6518518518518519\n",
      "Epoch 139 | loss 0.02142916829497726 - accuracy 0.6592592592592592\n",
      "Epoch 140 | loss 0.0217411701326017 - accuracy 0.6444444444444445\n",
      "Epoch 141 | loss 0.02153961768856755 - accuracy 0.6518518518518519\n",
      "Epoch 142 | loss 0.021546801814326534 - accuracy 0.6444444444444445\n",
      "Epoch 143 | loss 0.021491268387547245 - accuracy 0.674074074074074\n",
      "Epoch 144 | loss 0.02091337596928632 - accuracy 0.7111111111111111\n",
      "Epoch 145 | loss 0.021490988024958857 - accuracy 0.6666666666666666\n",
      "Epoch 146 | loss 0.021230018138885497 - accuracy 0.7037037037037037\n",
      "Epoch 147 | loss 0.02020147133756567 - accuracy 0.7037037037037037\n",
      "Epoch 148 | loss 0.0208751623277311 - accuracy 0.6814814814814815\n",
      "Epoch 149 | loss 0.020808972031981857 - accuracy 0.6962962962962963\n",
      "Epoch 150 | loss 0.02111599908934699 - accuracy 0.6888888888888889\n",
      "Epoch 151 | loss 0.02045433168058042 - accuracy 0.7185185185185186\n",
      "Epoch 152 | loss 0.020840762500409726 - accuracy 0.6888888888888889\n",
      "Epoch 153 | loss 0.020975055076457836 - accuracy 0.6962962962962963\n",
      "Epoch 154 | loss 0.02036666362373917 - accuracy 0.7037037037037037\n",
      "Epoch 155 | loss 0.020667993580853496 - accuracy 0.6888888888888889\n",
      "Epoch 156 | loss 0.02028324979322928 - accuracy 0.7481481481481481\n",
      "Epoch 157 | loss 0.020870139201482136 - accuracy 0.6962962962962963\n",
      "Epoch 158 | loss 0.01996451108543961 - accuracy 0.7185185185185186\n",
      "Epoch 159 | loss 0.02115732056123239 - accuracy 0.7185185185185186\n",
      "Epoch 160 | loss 0.01983803665196454 - accuracy 0.7111111111111111\n",
      "Epoch 161 | loss 0.019382908388420387 - accuracy 0.7185185185185186\n",
      "Epoch 162 | loss 0.019587968234662658 - accuracy 0.7333333333333333\n",
      "Epoch 163 | loss 0.019138783657992327 - accuracy 0.7185185185185186\n",
      "Epoch 164 | loss 0.020020944983870893 - accuracy 0.725925925925926\n",
      "Epoch 165 | loss 0.02041354709201389 - accuracy 0.7111111111111111\n",
      "Epoch 166 | loss 0.019834107381326183 - accuracy 0.6888888888888889\n",
      "Epoch 167 | loss 0.019380577626051727 - accuracy 0.7481481481481481\n",
      "Epoch 168 | loss 0.019181602089493363 - accuracy 0.7407407407407407\n",
      "Epoch 169 | loss 0.019066964255438912 - accuracy 0.7333333333333333\n",
      "Epoch 170 | loss 0.018941679265764025 - accuracy 0.7111111111111111\n",
      "Epoch 171 | loss 0.019865880851392393 - accuracy 0.6888888888888889\n",
      "Epoch 172 | loss 0.02010433342721727 - accuracy 0.7111111111111111\n",
      "Epoch 173 | loss 0.019831497580916794 - accuracy 0.7185185185185186\n",
      "Epoch 174 | loss 0.020231340549610278 - accuracy 0.7111111111111111\n",
      "Epoch 175 | loss 0.020309660611329255 - accuracy 0.7185185185185186\n",
      "Epoch 176 | loss 0.020248370038138494 - accuracy 0.6592592592592592\n",
      "Epoch 177 | loss 0.019160918615482473 - accuracy 0.7037037037037037\n",
      "Epoch 178 | loss 0.020319010593273023 - accuracy 0.725925925925926\n",
      "Epoch 179 | loss 0.01799831853972541 - accuracy 0.7925925925925926\n",
      "Epoch 180 | loss 0.019216058651606242 - accuracy 0.725925925925926\n",
      "Epoch 181 | loss 0.01956717857608089 - accuracy 0.6888888888888889\n",
      "Epoch 182 | loss 0.018924417319121183 - accuracy 0.7111111111111111\n",
      "Epoch 183 | loss 0.019051622240631668 - accuracy 0.725925925925926\n",
      "Epoch 184 | loss 0.019205708856935854 - accuracy 0.725925925925926\n",
      "Epoch 185 | loss 0.01922197386070534 - accuracy 0.7481481481481481\n",
      "Epoch 186 | loss 0.019651940133836535 - accuracy 0.7111111111111111\n",
      "Epoch 187 | loss 0.0189893901348114 - accuracy 0.7703703703703704\n",
      "Epoch 188 | loss 0.01937658080348262 - accuracy 0.725925925925926\n",
      "Epoch 189 | loss 0.01905603055600767 - accuracy 0.7407407407407407\n",
      "Epoch 190 | loss 0.017717012652644405 - accuracy 0.7333333333333333\n",
      "Epoch 191 | loss 0.018381270876637212 - accuracy 0.7111111111111111\n",
      "Epoch 192 | loss 0.018538788071385138 - accuracy 0.7555555555555555\n",
      "Epoch 193 | loss 0.01898447937435574 - accuracy 0.7185185185185186\n",
      "Epoch 194 | loss 0.018587488819051673 - accuracy 0.7333333333333333\n",
      "Epoch 195 | loss 0.0193873871255804 - accuracy 0.7185185185185186\n",
      "Epoch 196 | loss 0.018162656603036103 - accuracy 0.7333333333333333\n",
      "Epoch 197 | loss 0.019846122132407294 - accuracy 0.7037037037037037\n",
      "Epoch 198 | loss 0.018163295807661833 - accuracy 0.7555555555555555\n",
      "Epoch 199 | loss 0.01940355477509675 - accuracy 0.7111111111111111\n",
      "Epoch 200 | loss 0.018250343313923587 - accuracy 0.7407407407407407\n",
      "Epoch 201 | loss 0.018375765173523514 - accuracy 0.7407407407407407\n",
      "Epoch 202 | loss 0.0180176748169793 - accuracy 0.7481481481481481\n",
      "Epoch 203 | loss 0.017965451434806542 - accuracy 0.725925925925926\n",
      "Epoch 204 | loss 0.017834076616499158 - accuracy 0.7407407407407407\n",
      "Epoch 205 | loss 0.018755911897729943 - accuracy 0.7111111111111111\n",
      "Epoch 206 | loss 0.018159595904526888 - accuracy 0.7185185185185186\n",
      "Epoch 207 | loss 0.0175877312819163 - accuracy 0.7777777777777778\n",
      "Epoch 208 | loss 0.018108237231219255 - accuracy 0.7407407407407407\n",
      "Epoch 209 | loss 0.017509869513688263 - accuracy 0.7777777777777778\n",
      "Epoch 210 | loss 0.018381286991967095 - accuracy 0.7407407407407407\n",
      "Epoch 211 | loss 0.01808128312782005 - accuracy 0.7555555555555555\n",
      "Epoch 212 | loss 0.01744327313370175 - accuracy 0.7037037037037037\n",
      "Epoch 213 | loss 0.01782007239483021 - accuracy 0.7333333333333333\n",
      "Epoch 214 | loss 0.018352009190453423 - accuracy 0.7481481481481481\n",
      "Epoch 215 | loss 0.018489658059897246 - accuracy 0.7481481481481481\n",
      "Epoch 216 | loss 0.018045958324714943 - accuracy 0.762962962962963\n",
      "Epoch 217 | loss 0.018410480905462195 - accuracy 0.762962962962963\n",
      "Epoch 218 | loss 0.01786875813095658 - accuracy 0.7555555555555555\n",
      "Epoch 219 | loss 0.0179279245712139 - accuracy 0.762962962962963\n",
      "Epoch 220 | loss 0.01812536429475855 - accuracy 0.7407407407407407\n",
      "Epoch 221 | loss 0.019987682059959128 - accuracy 0.7333333333333333\n",
      "Epoch 222 | loss 0.017557399581979823 - accuracy 0.7481481481481481\n",
      "Epoch 223 | loss 0.017454769213994345 - accuracy 0.7555555555555555\n",
      "Epoch 224 | loss 0.01861930158403185 - accuracy 0.6962962962962963\n",
      "Epoch 225 | loss 0.019191340384659944 - accuracy 0.7333333333333333\n",
      "Epoch 226 | loss 0.01857548952102661 - accuracy 0.7333333333333333\n",
      "Epoch 227 | loss 0.017085238297780355 - accuracy 0.7333333333333333\n",
      "Epoch 228 | loss 0.017145251565509372 - accuracy 0.7111111111111111\n",
      "Epoch 229 | loss 0.018348563931606433 - accuracy 0.7111111111111111\n",
      "Epoch 230 | loss 0.017353558761102183 - accuracy 0.762962962962963\n",
      "Epoch 231 | loss 0.016234210795826383 - accuracy 0.762962962962963\n",
      "Epoch 232 | loss 0.017421210364059164 - accuracy 0.6888888888888889\n",
      "Epoch 233 | loss 0.017223431997829015 - accuracy 0.7555555555555555\n",
      "Epoch 234 | loss 0.017959172637374312 - accuracy 0.7481481481481481\n",
      "Epoch 235 | loss 0.017016234000523885 - accuracy 0.7407407407407407\n",
      "Epoch 236 | loss 0.017272900100107545 - accuracy 0.7555555555555555\n",
      "Epoch 237 | loss 0.018265020626562614 - accuracy 0.7777777777777778\n",
      "Epoch 238 | loss 0.017475224645049484 - accuracy 0.762962962962963\n",
      "Epoch 239 | loss 0.017308332964226052 - accuracy 0.7703703703703704\n",
      "Epoch 240 | loss 0.01697245549272608 - accuracy 0.7555555555555555\n",
      "Epoch 241 | loss 0.018185518737192506 - accuracy 0.762962962962963\n",
      "Epoch 242 | loss 0.017290224300490487 - accuracy 0.7851851851851852\n",
      "Epoch 243 | loss 0.016965528108455516 - accuracy 0.7777777777777778\n",
      "Epoch 244 | loss 0.017400019257156937 - accuracy 0.7407407407407407\n",
      "Epoch 245 | loss 0.017585566529521236 - accuracy 0.7481481481481481\n",
      "Epoch 246 | loss 0.017597672784769976 - accuracy 0.7555555555555555\n",
      "Epoch 247 | loss 0.01696546033576683 - accuracy 0.7851851851851852\n",
      "Epoch 248 | loss 0.017126200927628413 - accuracy 0.7481481481481481\n",
      "Epoch 249 | loss 0.017442133250059905 - accuracy 0.762962962962963\n",
      "Epoch 250 | loss 0.01616057786676619 - accuracy 0.7851851851851852\n",
      "Epoch 251 | loss 0.017985707521438597 - accuracy 0.725925925925926\n",
      "Epoch 252 | loss 0.01767289506064521 - accuracy 0.762962962962963\n",
      "Epoch 253 | loss 0.016719544706521212 - accuracy 0.7777777777777778\n",
      "Epoch 254 | loss 0.015404978725645278 - accuracy 0.7925925925925926\n",
      "Epoch 255 | loss 0.016730214379451894 - accuracy 0.7555555555555555\n",
      "Epoch 256 | loss 0.017253060031820228 - accuracy 0.725925925925926\n",
      "Epoch 257 | loss 0.015607473916477627 - accuracy 0.762962962962963\n",
      "Epoch 258 | loss 0.01612336547286422 - accuracy 0.7851851851851852\n",
      "Epoch 259 | loss 0.017338560466413144 - accuracy 0.7333333333333333\n",
      "Epoch 260 | loss 0.01725226210223304 - accuracy 0.7037037037037037\n",
      "Epoch 261 | loss 0.017531307207213506 - accuracy 0.7333333333333333\n",
      "Epoch 262 | loss 0.01790028534553669 - accuracy 0.762962962962963\n",
      "Epoch 263 | loss 0.016109717996032148 - accuracy 0.7407407407407407\n",
      "Epoch 264 | loss 0.015580631406218917 - accuracy 0.7555555555555555\n",
      "Epoch 265 | loss 0.016342028313212926 - accuracy 0.7481481481481481\n",
      "Epoch 266 | loss 0.01571041610505846 - accuracy 0.7851851851851852\n",
      "Epoch 267 | loss 0.016872322228219775 - accuracy 0.7407407407407407\n",
      "Epoch 268 | loss 0.017635602200472795 - accuracy 0.725925925925926\n",
      "Epoch 269 | loss 0.01864413078184481 - accuracy 0.7333333333333333\n",
      "Epoch 270 | loss 0.01662559763148979 - accuracy 0.7481481481481481\n",
      "Epoch 271 | loss 0.017122943313033493 - accuracy 0.7333333333333333\n",
      "Epoch 272 | loss 0.016815313476103322 - accuracy 0.7703703703703704\n",
      "Epoch 273 | loss 0.015814599560366738 - accuracy 0.7481481481481481\n",
      "Epoch 274 | loss 0.016219657990667553 - accuracy 0.762962962962963\n",
      "Epoch 275 | loss 0.01639695421413139 - accuracy 0.7555555555555555\n",
      "Epoch 276 | loss 0.017702734580746404 - accuracy 0.7481481481481481\n",
      "Epoch 277 | loss 0.01739933556980557 - accuracy 0.7407407407407407\n",
      "Epoch 278 | loss 0.016950211701569733 - accuracy 0.7407407407407407\n",
      "Epoch 279 | loss 0.01505243060765443 - accuracy 0.7555555555555555\n",
      "Epoch 280 | loss 0.017243829038408067 - accuracy 0.7407407407407407\n",
      "Epoch 281 | loss 0.01571356576901895 - accuracy 0.7777777777777778\n",
      "Epoch 282 | loss 0.016644005532617922 - accuracy 0.7185185185185186\n",
      "Epoch 283 | loss 0.016600993054884453 - accuracy 0.7333333333333333\n",
      "Epoch 284 | loss 0.01531797934461523 - accuracy 0.7703703703703704\n",
      "Epoch 285 | loss 0.015323205568172314 - accuracy 0.762962962962963\n",
      "Epoch 286 | loss 0.015792983991128426 - accuracy 0.7777777777777778\n",
      "Epoch 287 | loss 0.01593784910661203 - accuracy 0.725925925925926\n",
      "Epoch 288 | loss 0.015237155004783913 - accuracy 0.7333333333333333\n",
      "Epoch 289 | loss 0.016503289452305548 - accuracy 0.762962962962963\n",
      "Epoch 290 | loss 0.0164777719312244 - accuracy 0.7407407407407407\n",
      "Epoch 291 | loss 0.015212106704711913 - accuracy 0.8074074074074075\n",
      "Epoch 292 | loss 0.016527247428894044 - accuracy 0.7703703703703704\n",
      "Epoch 293 | loss 0.01667122079266442 - accuracy 0.7333333333333333\n",
      "Epoch 294 | loss 0.016357044378916424 - accuracy 0.7703703703703704\n",
      "Epoch 295 | loss 0.015571559137768216 - accuracy 0.762962962962963\n",
      "Epoch 296 | loss 0.01711118155055576 - accuracy 0.7555555555555555\n",
      "Epoch 297 | loss 0.016614769564734566 - accuracy 0.725925925925926\n",
      "Epoch 298 | loss 0.0150074718175111 - accuracy 0.7851851851851852\n",
      "Epoch 299 | loss 0.016801241923261573 - accuracy 0.7777777777777778\n",
      "Epoch 300 | loss 0.01727961235576206 - accuracy 0.7333333333333333\n",
      "Epoch 301 | loss 0.01625421267968637 - accuracy 0.7925925925925926\n",
      "Epoch 302 | loss 0.016130103446819165 - accuracy 0.7777777777777778\n",
      "Epoch 303 | loss 0.015220808872470149 - accuracy 0.762962962962963\n",
      "Epoch 304 | loss 0.016474675249170373 - accuracy 0.7703703703703704\n",
      "Epoch 305 | loss 0.016236534935456737 - accuracy 0.7407407407407407\n",
      "Epoch 306 | loss 0.01764617959658305 - accuracy 0.762962962962963\n",
      "Epoch 307 | loss 0.016845222534956756 - accuracy 0.7777777777777778\n",
      "Epoch 308 | loss 0.0158354550048157 - accuracy 0.762962962962963\n",
      "Epoch 309 | loss 0.015166210852287434 - accuracy 0.7407407407407407\n",
      "Epoch 310 | loss 0.016197075225688792 - accuracy 0.8222222222222222\n",
      "Epoch 311 | loss 0.015198347634739345 - accuracy 0.762962962962963\n",
      "Epoch 312 | loss 0.014947181719320793 - accuracy 0.7703703703703704\n",
      "Epoch 313 | loss 0.016735346449746027 - accuracy 0.7481481481481481\n",
      "Epoch 314 | loss 0.015579421763066892 - accuracy 0.7555555555555555\n",
      "Epoch 315 | loss 0.01555857989523146 - accuracy 0.8\n",
      "Epoch 316 | loss 0.01638804276784261 - accuracy 0.7703703703703704\n",
      "Epoch 317 | loss 0.015640391133449696 - accuracy 0.7777777777777778\n",
      "Epoch 318 | loss 0.014815348993848872 - accuracy 0.7851851851851852\n",
      "Epoch 319 | loss 0.016769930830708258 - accuracy 0.7333333333333333\n",
      "Epoch 320 | loss 0.016602252920468647 - accuracy 0.7777777777777778\n",
      "Epoch 321 | loss 0.015354328133441784 - accuracy 0.7777777777777778\n",
      "Epoch 322 | loss 0.014180687842545685 - accuracy 0.8\n",
      "Epoch 323 | loss 0.016687059071328905 - accuracy 0.7851851851851852\n",
      "Epoch 324 | loss 0.015169753299819098 - accuracy 0.7481481481481481\n",
      "Epoch 325 | loss 0.018053345989297937 - accuracy 0.7777777777777778\n",
      "Epoch 326 | loss 0.014766195857966388 - accuracy 0.7703703703703704\n",
      "Epoch 327 | loss 0.014418574450192628 - accuracy 0.7925925925925926\n",
      "Epoch 328 | loss 0.01506351629892985 - accuracy 0.8\n",
      "Epoch 329 | loss 0.014465585902885155 - accuracy 0.7555555555555555\n",
      "Epoch 330 | loss 0.014364482627974616 - accuracy 0.7851851851851852\n",
      "Epoch 331 | loss 0.015466001740208379 - accuracy 0.7851851851851852\n",
      "Epoch 332 | loss 0.014910170104768541 - accuracy 0.7777777777777778\n",
      "Epoch 333 | loss 0.01570866792290299 - accuracy 0.8148148148148148\n",
      "Epoch 334 | loss 0.016580383645163642 - accuracy 0.7481481481481481\n",
      "Epoch 335 | loss 0.016627862718370225 - accuracy 0.7481481481481481\n",
      "Epoch 336 | loss 0.015214948300962094 - accuracy 0.7481481481481481\n",
      "Epoch 337 | loss 0.01526279107288078 - accuracy 0.8\n",
      "Epoch 338 | loss 0.016420162938259267 - accuracy 0.762962962962963\n",
      "Epoch 339 | loss 0.014987302599129853 - accuracy 0.7851851851851852\n",
      "Epoch 340 | loss 0.01713772416114807 - accuracy 0.7703703703703704\n",
      "Epoch 341 | loss 0.01612500724969087 - accuracy 0.7851851851851852\n",
      "Epoch 342 | loss 0.014746281173494127 - accuracy 0.7777777777777778\n",
      "Epoch 343 | loss 0.01578548694098437 - accuracy 0.7481481481481481\n",
      "Epoch 344 | loss 0.014957451709994563 - accuracy 0.7851851851851852\n",
      "Epoch 345 | loss 0.015454535241480227 - accuracy 0.7925925925925926\n",
      "Epoch 346 | loss 0.013991342484951019 - accuracy 0.8074074074074075\n",
      "Epoch 347 | loss 0.015592269765006172 - accuracy 0.7851851851851852\n",
      "Epoch 348 | loss 0.014699262435789461 - accuracy 0.8222222222222222\n",
      "Epoch 349 | loss 0.014136777211118627 - accuracy 0.7851851851851852\n",
      "Epoch 350 | loss 0.01710649640471847 - accuracy 0.7925925925925926\n",
      "Epoch 351 | loss 0.013262805729000657 - accuracy 0.8074074074074075\n",
      "Epoch 352 | loss 0.014914535151587593 - accuracy 0.7925925925925926\n",
      "Epoch 353 | loss 0.016874069858480382 - accuracy 0.762962962962963\n",
      "Epoch 354 | loss 0.01564567850695716 - accuracy 0.7925925925925926\n",
      "Epoch 355 | loss 0.015404613592006542 - accuracy 0.7333333333333333\n",
      "Epoch 356 | loss 0.015408794416321649 - accuracy 0.8222222222222222\n",
      "Epoch 357 | loss 0.01608000574288545 - accuracy 0.7851851851851852\n",
      "Epoch 358 | loss 0.014376703015080206 - accuracy 0.8\n",
      "Epoch 359 | loss 0.015221659342447917 - accuracy 0.8148148148148148\n",
      "Epoch 360 | loss 0.015061725731249209 - accuracy 0.7851851851851852\n",
      "Epoch 361 | loss 0.016386881249922294 - accuracy 0.7333333333333333\n",
      "Epoch 362 | loss 0.01536231537659963 - accuracy 0.7777777777777778\n",
      "Epoch 363 | loss 0.015407352094297055 - accuracy 0.7703703703703704\n",
      "Epoch 364 | loss 0.015875406673660986 - accuracy 0.7555555555555555\n",
      "Epoch 365 | loss 0.016455450102134988 - accuracy 0.7481481481481481\n",
      "Epoch 366 | loss 0.014509075217776828 - accuracy 0.7925925925925926\n",
      "Epoch 367 | loss 0.014427576020911888 - accuracy 0.8222222222222222\n",
      "Epoch 368 | loss 0.015365334462236474 - accuracy 0.7925925925925926\n",
      "Epoch 369 | loss 0.014909598341694585 - accuracy 0.8148148148148148\n",
      "Epoch 370 | loss 0.014707519831480803 - accuracy 0.8148148148148148\n",
      "Epoch 371 | loss 0.014360895311390912 - accuracy 0.8148148148148148\n",
      "Epoch 372 | loss 0.014715156511024192 - accuracy 0.8148148148148148\n",
      "Epoch 373 | loss 0.01373933321899838 - accuracy 0.8222222222222222\n",
      "Epoch 374 | loss 0.015269448304617846 - accuracy 0.7851851851851852\n",
      "Epoch 375 | loss 0.015331651987852874 - accuracy 0.7925925925925926\n",
      "Epoch 376 | loss 0.015110468533304002 - accuracy 0.7851851851851852\n",
      "Epoch 377 | loss 0.014098296066125234 - accuracy 0.7925925925925926\n",
      "Epoch 378 | loss 0.014336614586688855 - accuracy 0.8296296296296296\n",
      "Epoch 379 | loss 0.014909876827840451 - accuracy 0.7925925925925926\n",
      "Epoch 380 | loss 0.014643271874498438 - accuracy 0.7777777777777778\n",
      "Epoch 381 | loss 0.01592599164556574 - accuracy 0.8074074074074075\n",
      "Epoch 382 | loss 0.01453019380569458 - accuracy 0.7777777777777778\n",
      "Epoch 383 | loss 0.01436301867167155 - accuracy 0.8148148148148148\n",
      "Epoch 384 | loss 0.014241433750700068 - accuracy 0.8222222222222222\n",
      "Epoch 385 | loss 0.01469281205424556 - accuracy 0.8222222222222222\n",
      "Epoch 386 | loss 0.01411442635235963 - accuracy 0.7851851851851852\n",
      "Epoch 387 | loss 0.014402485500883173 - accuracy 0.7925925925925926\n",
      "Epoch 388 | loss 0.014206802955380193 - accuracy 0.8074074074074075\n",
      "Epoch 389 | loss 0.0149377410058622 - accuracy 0.7925925925925926\n",
      "Epoch 390 | loss 0.014151351595366443 - accuracy 0.8222222222222222\n",
      "Epoch 391 | loss 0.01315687718214812 - accuracy 0.7925925925925926\n",
      "Epoch 392 | loss 0.014242696872463934 - accuracy 0.837037037037037\n",
      "Epoch 393 | loss 0.013621059667181086 - accuracy 0.8148148148148148\n",
      "Epoch 394 | loss 0.013766440252463022 - accuracy 0.8222222222222222\n",
      "Epoch 395 | loss 0.014933268560303583 - accuracy 0.8\n",
      "Epoch 396 | loss 0.014279765773702551 - accuracy 0.7851851851851852\n",
      "Epoch 397 | loss 0.014969516793886821 - accuracy 0.7555555555555555\n",
      "Epoch 398 | loss 0.014493920626463713 - accuracy 0.8074074074074075\n",
      "Epoch 399 | loss 0.014424325305002707 - accuracy 0.8\n",
      "Epoch 400 | loss 0.015509648013997962 - accuracy 0.8\n",
      "Epoch 401 | loss 0.015145072672102187 - accuracy 0.7925925925925926\n",
      "Epoch 402 | loss 0.014469556565637942 - accuracy 0.7777777777777778\n",
      "Epoch 403 | loss 0.01499750139536681 - accuracy 0.7851851851851852\n",
      "Epoch 404 | loss 0.01633242788138213 - accuracy 0.7777777777777778\n",
      "Epoch 405 | loss 0.01499653955300649 - accuracy 0.762962962962963\n",
      "Epoch 406 | loss 0.01531905785754875 - accuracy 0.7777777777777778\n",
      "Epoch 407 | loss 0.01534544582720156 - accuracy 0.7851851851851852\n",
      "Epoch 408 | loss 0.01562417811817593 - accuracy 0.8296296296296296\n",
      "Epoch 409 | loss 0.013665914921848862 - accuracy 0.7925925925925926\n",
      "Epoch 410 | loss 0.015055248417236187 - accuracy 0.8074074074074075\n",
      "Epoch 411 | loss 0.014861658767417626 - accuracy 0.7925925925925926\n",
      "Epoch 412 | loss 0.015581826589725636 - accuracy 0.7925925925925926\n",
      "Epoch 413 | loss 0.014432746282330267 - accuracy 0.8074074074074075\n",
      "Epoch 414 | loss 0.013949296319926226 - accuracy 0.8222222222222222\n",
      "Epoch 415 | loss 0.013591695935637863 - accuracy 0.8296296296296296\n",
      "Epoch 416 | loss 0.013863517564755899 - accuracy 0.8296296296296296\n",
      "Epoch 417 | loss 0.014696602137000473 - accuracy 0.7851851851851852\n",
      "Epoch 418 | loss 0.014987335492063452 - accuracy 0.7777777777777778\n",
      "Epoch 419 | loss 0.01468495285069501 - accuracy 0.8148148148148148\n",
      "Epoch 420 | loss 0.013317507615795842 - accuracy 0.8074074074074075\n",
      "Epoch 421 | loss 0.014402646047097666 - accuracy 0.7851851851851852\n",
      "Epoch 422 | loss 0.013742257102772042 - accuracy 0.8222222222222222\n",
      "Epoch 423 | loss 0.014681154268759268 - accuracy 0.8222222222222222\n",
      "Epoch 424 | loss 0.015558783102918554 - accuracy 0.7703703703703704\n",
      "Epoch 425 | loss 0.015289839384732423 - accuracy 0.8074074074074075\n",
      "Epoch 426 | loss 0.014871005493181723 - accuracy 0.7777777777777778\n",
      "Epoch 427 | loss 0.015252422955301072 - accuracy 0.7851851851851852\n",
      "Epoch 428 | loss 0.015100903533123157 - accuracy 0.7703703703703704\n",
      "Epoch 429 | loss 0.013346532152758704 - accuracy 0.8222222222222222\n",
      "Epoch 430 | loss 0.014836928248405457 - accuracy 0.7851851851851852\n",
      "Epoch 431 | loss 0.014298009099783722 - accuracy 0.7777777777777778\n",
      "Epoch 432 | loss 0.013764313304865801 - accuracy 0.8296296296296296\n",
      "Epoch 433 | loss 0.013772428035736084 - accuracy 0.7925925925925926\n",
      "Epoch 434 | loss 0.013888504990824946 - accuracy 0.8\n",
      "Epoch 435 | loss 0.012214969705652308 - accuracy 0.8740740740740741\n",
      "Epoch 436 | loss 0.015988793748396415 - accuracy 0.7851851851851852\n",
      "Epoch 437 | loss 0.014269593247660884 - accuracy 0.8074074074074075\n",
      "Epoch 438 | loss 0.013641085999983328 - accuracy 0.8074074074074075\n",
      "Epoch 439 | loss 0.016479117230132775 - accuracy 0.7777777777777778\n",
      "Epoch 440 | loss 0.014845995329044483 - accuracy 0.8222222222222222\n",
      "Epoch 441 | loss 0.01196663357593395 - accuracy 0.837037037037037\n",
      "Epoch 442 | loss 0.015026856903676633 - accuracy 0.8\n",
      "Epoch 443 | loss 0.015532598340952839 - accuracy 0.7777777777777778\n",
      "Epoch 444 | loss 0.011680917497034426 - accuracy 0.8296296296296296\n",
      "Epoch 445 | loss 0.013030412130885655 - accuracy 0.8148148148148148\n",
      "Epoch 446 | loss 0.014816134671370189 - accuracy 0.762962962962963\n",
      "Epoch 447 | loss 0.013475056268550731 - accuracy 0.8296296296296296\n",
      "Epoch 448 | loss 0.012894888939680877 - accuracy 0.837037037037037\n",
      "Epoch 449 | loss 0.013120953297173535 - accuracy 0.8\n",
      "Epoch 450 | loss 0.013999246226416694 - accuracy 0.8074074074074075\n",
      "Epoch 451 | loss 0.013042163021034664 - accuracy 0.837037037037037\n",
      "Epoch 452 | loss 0.013889563414785597 - accuracy 0.8518518518518519\n",
      "Epoch 453 | loss 0.015227445408150003 - accuracy 0.7777777777777778\n",
      "Epoch 454 | loss 0.014006105230914221 - accuracy 0.8296296296296296\n",
      "Epoch 455 | loss 0.013373033426426074 - accuracy 0.8444444444444444\n",
      "Epoch 456 | loss 0.01353751641732675 - accuracy 0.8148148148148148\n",
      "Epoch 457 | loss 0.014470356261288678 - accuracy 0.7851851851851852\n",
      "Epoch 458 | loss 0.014158630260714778 - accuracy 0.8296296296296296\n",
      "Epoch 459 | loss 0.014654605697702478 - accuracy 0.762962962962963\n",
      "Epoch 460 | loss 0.01298736455263915 - accuracy 0.8296296296296296\n",
      "Epoch 461 | loss 0.014430821273061964 - accuracy 0.8074074074074075\n",
      "Epoch 462 | loss 0.012330935619495532 - accuracy 0.8148148148148148\n",
      "Epoch 463 | loss 0.012533056073718601 - accuracy 0.837037037037037\n",
      "Epoch 464 | loss 0.012655895341325689 - accuracy 0.837037037037037\n",
      "Epoch 465 | loss 0.014992735672880102 - accuracy 0.7777777777777778\n",
      "Epoch 466 | loss 0.013114937808778551 - accuracy 0.8296296296296296\n",
      "Epoch 467 | loss 0.01369816881638986 - accuracy 0.8148148148148148\n",
      "Epoch 468 | loss 0.011808379877496649 - accuracy 0.8148148148148148\n",
      "Epoch 469 | loss 0.011383537341047216 - accuracy 0.8592592592592593\n",
      "Epoch 470 | loss 0.016659401964258264 - accuracy 0.8222222222222222\n",
      "Epoch 471 | loss 0.01432834631866879 - accuracy 0.7703703703703704\n",
      "Epoch 472 | loss 0.01431581786385289 - accuracy 0.8074074074074075\n",
      "Epoch 473 | loss 0.013111856524591093 - accuracy 0.7925925925925926\n",
      "Epoch 474 | loss 0.014349344924644188 - accuracy 0.8148148148148148\n",
      "Epoch 475 | loss 0.012952423813166442 - accuracy 0.8074074074074075\n",
      "Epoch 476 | loss 0.012273074962474682 - accuracy 0.8444444444444444\n",
      "Epoch 477 | loss 0.01478355637303105 - accuracy 0.8296296296296296\n",
      "Epoch 478 | loss 0.014812576439645555 - accuracy 0.8222222222222222\n",
      "Epoch 479 | loss 0.013506379392411973 - accuracy 0.8148148148148148\n",
      "Epoch 480 | loss 0.013408697092974627 - accuracy 0.8148148148148148\n",
      "Epoch 481 | loss 0.015960438052813213 - accuracy 0.762962962962963\n",
      "Epoch 482 | loss 0.013043450978067186 - accuracy 0.8222222222222222\n",
      "Epoch 483 | loss 0.012852136459615495 - accuracy 0.7925925925925926\n",
      "Epoch 484 | loss 0.014131974898002766 - accuracy 0.7925925925925926\n",
      "Epoch 485 | loss 0.014471531686959443 - accuracy 0.7925925925925926\n",
      "Epoch 486 | loss 0.0135598032562821 - accuracy 0.8222222222222222\n",
      "Epoch 487 | loss 0.012629134566695602 - accuracy 0.837037037037037\n",
      "Epoch 488 | loss 0.013283199568589529 - accuracy 0.8\n",
      "Epoch 489 | loss 0.01348405436233238 - accuracy 0.8444444444444444\n",
      "Epoch 490 | loss 0.012847515057634424 - accuracy 0.837037037037037\n",
      "Epoch 491 | loss 0.012699668054227476 - accuracy 0.7925925925925926\n",
      "Epoch 492 | loss 0.013830030461152394 - accuracy 0.7851851851851852\n",
      "Epoch 493 | loss 0.014827135536405776 - accuracy 0.7777777777777778\n",
      "Epoch 494 | loss 0.012429674797587924 - accuracy 0.837037037037037\n",
      "Epoch 495 | loss 0.012365922111052054 - accuracy 0.837037037037037\n",
      "Epoch 496 | loss 0.012830466804681001 - accuracy 0.837037037037037\n",
      "Epoch 497 | loss 0.012540208024007302 - accuracy 0.7925925925925926\n",
      "Epoch 498 | loss 0.013754721261836864 - accuracy 0.8148148148148148\n",
      "Epoch 499 | loss 0.013824946571279455 - accuracy 0.8074074074074075\n",
      "Epoch 500 | loss 0.01389216372260341 - accuracy 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "class capilabDS(Dataset):\n",
    "    def __init__(self, x, y, device = 'cpu'):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.device = device\n",
    "        self.num_class = np.unique(self.y)\n",
    "        ohe = OneHotEncoder(sparse_output = False)\n",
    "        self.y = ohe.fit_transform(self.y, self.num_class)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x = torch.Tensor(self.x[index,:,:,:]).to(self.device, torch.float32)\n",
    "        y = torch.Tensor(self.y[index, :]).to(self.device, torch.float32)\n",
    "\n",
    "        return (x, y)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_data = capilabDS(xt, yt, device = device)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "\n",
    "model = EEGNet(chunk_size=1001, num_electrodes=8, num_classes=2, F1 = 8, F2 =16,\n",
    "D = 3, kernel_1 = 64, kernel_2 = 16, dropout = 0.5).to(device)\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-4, eps=1e-7)\n",
    "\n",
    "epochs = 500\n",
    "epoch_loss = []\n",
    "for epoch in range(epochs):\n",
    "    bloss = 0\n",
    "    bacc = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x, y = batch\n",
    "        optim.zero_grad()\n",
    "        yhat = model(x)\n",
    "        \n",
    "        loss = criteria(yhat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "        bloss += loss.item()\n",
    "        pred = np.argmax(nn.functional.softmax(yhat, 1).detach().cpu().numpy(), 1)\n",
    "        target = np.argmax(y.detach().cpu().numpy(), 1)\n",
    "        \n",
    "        bacc += np.sum(pred == target)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1:3d} | loss {bloss / len(train_loader.dataset)} - accuracy {bacc / len(train_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 1 1 1 1 0 0 0 1 1] [1 0 0 0 0 0 1 1 1 1 0 0 0 1 0]\n",
      "accuracy 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "test_data = capilabDS(xv, yv, device = device)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle = True)\n",
    "bacc = 0\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        x, y = batch\n",
    "        yhat = model(x)\n",
    "\n",
    "        pred = np.argmax(nn.functional.softmax(yhat, 1).detach().cpu().numpy(), 1)\n",
    "        target = np.argmax(y.detach().cpu().numpy(), 1)\n",
    "        bacc += np.sum(pred == target)\n",
    "        print(target, pred)\n",
    "    print(f\"accuracy {bacc / len(test_loader.dataset) * 100}%\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
